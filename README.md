ğŸ§  AI-Based Image Classification & Text-to-Image Search

Hackathon Domain: AI / ML
Team Size: 4
Hackathon: GEHU Himtal Hackathon

ğŸ“Œ Problem Statement

Finding relevant images from large datasets using natural language descriptions is still a challenge in many real-world applications such as surveillance, e-commerce, media management, and smart search engines.

Our project solves this by combining:

Image Classification (Animal vs Person)

Text-to-Image Semantic Search (e.g., â€œperson wearing red dressâ€)

This creates an intelligent system that understands both visual content and human language.

ğŸš€ Solution Overview

Our system consists of two AI pipelines:

Image Classification Pipeline

Classifies an input image into predefined categories (Animal / Person).

Built using MobileNetV2 (Transfer Learning).

Text-to-Image Search Pipeline

Takes a natural language query.

Finds the most semantically similar image using CLIP (OpenAI) embeddings.

Both pipelines are lightweight, modular, and hackathon-ready.

ğŸ—‚ï¸ Project Structure
NEW FOLDER (2)
â”‚
â”œâ”€â”€ Dataset/
â”‚   â”œâ”€â”€ animal/
â”‚   â””â”€â”€ person/
â”‚
â”œâ”€â”€ classifier_train.py
â”œâ”€â”€ classifier_predict.py
â”œâ”€â”€ classifier_model.h5
â”œâ”€â”€ labels.txt
â”œâ”€â”€ text_image_search.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

ğŸ” System Flow (High-Level)
Image Classification Flow
Input Image
     â†“
Image Preprocessing (224x224)
     â†“
MobileNetV2 Feature Extractor
     â†“
Dense Softmax Layer
     â†“
Class Prediction + Confidence

Text-to-Image Search Flow
Text Query
     â†“
CLIP Text Encoder
     â†“
Image Embeddings (CLIP Image Encoder)
     â†“
Cosine Similarity Matching
     â†“
Best Matched Image

ğŸ§© Basic System Diagram (Birdâ€™s Eye View)
User
 â”‚
 â”œâ”€â”€ Image Input â”€â”€â–¶ Image Classifier (TensorFlow)
 â”‚                   â”‚
 â”‚                   â””â”€â”€ Output: Class + Confidence
 â”‚
 â””â”€â”€ Text Query â”€â”€â–¶ CLIP Model (PyTorch)
                     â”‚
                     â””â”€â”€ Output: Best Matching Image

âš™ï¸ Technologies Used
Component	Technology
Image Classification	TensorFlow, Keras
Model Architecture	MobileNetV2
Text-Image Search	OpenAI CLIP
Backend Logic	Python
Image Processing	PIL
Hardware Support	CPU / GPU

ğŸ“ˆ Scalability & Growth Plan
How the system handles more users:

Pre-compute and store image embeddings.

Use vector databases (FAISS / Pinecone) in future.

Separate inference services for classification & search.

Failure Handling:

Input validation for images & text

Graceful fallback to CPU if GPU unavailable

Modular design â†’ failure in one module doesnâ€™t crash system

ğŸ§ª Current Limitations (Round 1)

Small dataset (hackathon constraint)

CLI-based interaction

No web interface yet

ğŸ”® Planned Improvements for Round 2 (Mandatory Section)

âœ”ï¸ Web Interface (Flask / FastAPI)
âœ”ï¸ Multi-class Classification (beyond Animal/Person)
âœ”ï¸ Advanced Text Queries (attributes, actions, clothing)
âœ”ï¸ Vector Database Integration
âœ”ï¸ User Upload & Search History
âœ”ï¸ Better Evaluation Metrics

ğŸ† Originality & Innovation

Combines supervised classification with zero-shot semantic search

Uses state-of-the-art CLIP model

Fully original pipeline design

No copied templates or boilerplate projects

